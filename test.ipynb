{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig, DebertaV2ForSequenceClassification\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DebertaV2ForSequenceClassification(\n",
      "  (deberta): DebertaV2Model(\n",
      "    (embeddings): DebertaV2Embeddings(\n",
      "      (word_embeddings): Embedding(128100, 1024, padding_idx=0)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
      "      (dropout): StableDropout()\n",
      "    )\n",
      "    (encoder): DebertaV2Encoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-23): 24 x DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (rel_embeddings): Embedding(512, 1024)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (pooler): ContextPooler(\n",
      "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (dropout): StableDropout()\n",
      "  )\n",
      "  (classifier): Linear(in_features=1024, out_features=1, bias=True)\n",
      "  (dropout): StableDropout()\n",
      ")\n",
      "<class 'transformers.models.deberta_v2.modeling_deberta_v2.DebertaV2ForSequenceClassification'>\n"
     ]
    }
   ],
   "source": [
    "reward_name = \"/home/tiger/.cache/huggingface/hub/models--OpenAssistant--reward-model-deberta-v3-large-v2/snapshots/c355404efa9ad2ad069f3a197cae0523c14244fc\"\n",
    "model: DebertaV2ForSequenceClassification = AutoModelForSequenceClassification.from_pretrained(reward_name)\n",
    "print(model)\n",
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52002\n"
     ]
    }
   ],
   "source": [
    "with open(\"/opt/tiger/MoDS/quality-evaluation/input.json\", \"r\") as f:\n",
    "    data = f.read()\n",
    "    data = json.loads(data)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.dumps(data[:1000])\n",
    "with open(\"/opt/tiger/MoDS/quality-evaluation/data.json\", \"w\") as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiger/.local/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "2024-05-26 17:30:16,005\tINFO worker.py:1582 -- Calling ray.init() again after it has already been called.\n"
     ]
    }
   ],
   "source": [
    "model = LLM(model=\"gpt2\", tensor_parallel_size=6, dtype=\"float16\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2225c667b14e0d8c3e6e9f6534e212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/2.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "617120e29e0748e6a889d31e947cc177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174dd6ceb75f473d81af701e493d7fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/212M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9772e431720a401f92303e2d28cbb610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efedc8a5e7b54a72ad05ce70e80ea30f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"TIGER-Lab/MathInstruct\", cache_dir=\"/mnt/bn/data-tns-live-llm/leon/datasets/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "df = pl.read_parquet(\"/opt/tiger/MoDS/code.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 3)\n",
      "┌──────────────────────────────────┬─────────────────────────────┬─────────────────────────────────┐\n",
      "│ instruction                      ┆ input                       ┆ output                          │\n",
      "│ ---                              ┆ ---                         ┆ ---                             │\n",
      "│ str                              ┆ str                         ┆ str                             │\n",
      "╞══════════════════════════════════╪═════════════════════════════╪═════════════════════════════════╡\n",
      "│ Create a function that takes a…  ┆                             ┆ def f(x):                       │\n",
      "│                                  ┆                             ┆     \"\"\"                         │\n",
      "│                                  ┆                             ┆     Takes a …                   │\n",
      "│ Generate a unique 8 character …  ┆                             ┆ import string                   │\n",
      "│                                  ┆                             ┆ import random                   │\n",
      "│                                  ┆                             ┆                                 │\n",
      "│                                  ┆                             ┆ d…                              │\n",
      "│ Given a course consisting of 5…  ┆ Lessons = [\"Python Basics\", ┆ def display_first_lesson(lesso… │\n",
      "│                                  ┆ \"J…                         ┆                                 │\n",
      "│ Create an algorithm to encoura…  ┆                             ┆ One algorithm to encourage wor… │\n",
      "│ Write a JavaScript that change…  ┆                             ┆ document.getElementById(\"myPar… │\n",
      "└──────────────────────────────────┴─────────────────────────────┴─────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 3)\n",
      "┌────────────────────────────────┬────────────────────────────────┬────────────────────────────────┐\n",
      "│ source                         ┆ instruction                    ┆ output                         │\n",
      "│ ---                            ┆ ---                            ┆ ---                            │\n",
      "│ str                            ┆ str                            ┆ str                            │\n",
      "╞════════════════════════════════╪════════════════════════════════╪════════════════════════════════╡\n",
      "│ data/CoT/aqua_rat.json         ┆ The distance between two       ┆ Let's think about the          │\n",
      "│                                ┆ stars…                         ┆ multi-ch…                      │\n",
      "│ data/CoT/aqua_rat.json         ┆ How many ways can the letters  ┆ Let's solve the multi-choice   │\n",
      "│                                ┆ …                              ┆ q…                             │\n",
      "│ data/PoT/aqua_rat_filtered.jso ┆ A team of six entered for a    ┆ answers = ['A', 'B', 'C',      │\n",
      "│ …                              ┆ sh…                            ┆ 'D',…                          │\n",
      "│ data/CoT/gsm_rft.json          ┆ A psychiatrist has 4 patients  ┆ The second patient needs 6+5   │\n",
      "│                                ┆ …                              ┆ =…                             │\n",
      "│ data/PoT/aqua_rat_filtered.jso ┆ The radius of a wheel is 22.4  ┆ radius = 22.4                  │\n",
      "│ …                              ┆ …                              ┆ resolutions = 50…              │\n",
      "└────────────────────────────────┴────────────────────────────────┴────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "data = pl.read_json(\"/opt/tiger/MoDS/MathInstruct.json\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t1 = torch.load(\"/opt/tiger/Cherry_LLM/code_data_pre.pt\")\n",
    "print(type(t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ppl': [tensor(18.6185), 0, 0], 'sent_emb': [tensor([[-0.3425,  0.0562,  0.7246,  ..., -0.0523, -0.9365, -1.1855]],\n",
      "       dtype=torch.float16), 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(t1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
