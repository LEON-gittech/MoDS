{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig, DebertaV2ForSequenceClassification\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DebertaV2ForSequenceClassification(\n",
      "  (deberta): DebertaV2Model(\n",
      "    (embeddings): DebertaV2Embeddings(\n",
      "      (word_embeddings): Embedding(128100, 1024, padding_idx=0)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
      "      (dropout): StableDropout()\n",
      "    )\n",
      "    (encoder): DebertaV2Encoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-23): 24 x DebertaV2Layer(\n",
      "          (attention): DebertaV2Attention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaV2SelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaV2Intermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaV2Output(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (rel_embeddings): Embedding(512, 1024)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (pooler): ContextPooler(\n",
      "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (dropout): StableDropout()\n",
      "  )\n",
      "  (classifier): Linear(in_features=1024, out_features=1, bias=True)\n",
      "  (dropout): StableDropout()\n",
      ")\n",
      "<class 'transformers.models.deberta_v2.modeling_deberta_v2.DebertaV2ForSequenceClassification'>\n"
     ]
    }
   ],
   "source": [
    "reward_name = \"/home/tiger/.cache/huggingface/hub/models--OpenAssistant--reward-model-deberta-v3-large-v2/snapshots/c355404efa9ad2ad069f3a197cae0523c14244fc\"\n",
    "model: DebertaV2ForSequenceClassification = AutoModelForSequenceClassification.from_pretrained(reward_name)\n",
    "print(model)\n",
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52002\n"
     ]
    }
   ],
   "source": [
    "with open(\"/opt/tiger/MoDS/quality-evaluation/input.json\", \"r\") as f:\n",
    "    data = f.read()\n",
    "    data = json.loads(data)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.dumps(data[:1000])\n",
    "with open(\"/opt/tiger/MoDS/quality-evaluation/data.json\", \"w\") as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiger/.local/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "2024-05-26 17:30:16,005\tINFO worker.py:1582 -- Calling ray.init() again after it has already been called.\n"
     ]
    }
   ],
   "source": [
    "model = LLM(model=\"gpt2\", tensor_parallel_size=6, dtype=\"float16\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2225c667b14e0d8c3e6e9f6534e212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/2.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "617120e29e0748e6a889d31e947cc177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174dd6ceb75f473d81af701e493d7fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/212M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9772e431720a401f92303e2d28cbb610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efedc8a5e7b54a72ad05ce70e80ea30f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"TIGER-Lab/MathInstruct\", cache_dir=\"/mnt/bn/data-tns-live-llm/leon/datasets/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "df = pl.read_parquet(\"/opt/tiger/MoDS/code.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 3)\n",
      "┌──────────────────────────────────┬─────────────────────────────┬─────────────────────────────────┐\n",
      "│ instruction                      ┆ input                       ┆ output                          │\n",
      "│ ---                              ┆ ---                         ┆ ---                             │\n",
      "│ str                              ┆ str                         ┆ str                             │\n",
      "╞══════════════════════════════════╪═════════════════════════════╪═════════════════════════════════╡\n",
      "│ Create a function that takes a…  ┆                             ┆ def f(x):                       │\n",
      "│                                  ┆                             ┆     \"\"\"                         │\n",
      "│                                  ┆                             ┆     Takes a …                   │\n",
      "│ Generate a unique 8 character …  ┆                             ┆ import string                   │\n",
      "│                                  ┆                             ┆ import random                   │\n",
      "│                                  ┆                             ┆                                 │\n",
      "│                                  ┆                             ┆ d…                              │\n",
      "│ Given a course consisting of 5…  ┆ Lessons = [\"Python Basics\", ┆ def display_first_lesson(lesso… │\n",
      "│                                  ┆ \"J…                         ┆                                 │\n",
      "│ Create an algorithm to encoura…  ┆                             ┆ One algorithm to encourage wor… │\n",
      "│ Write a JavaScript that change…  ┆                             ┆ document.getElementById(\"myPar… │\n",
      "└──────────────────────────────────┴─────────────────────────────┴─────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 3)\n",
      "┌────────────────────────────────┬────────────────────────────────┬────────────────────────────────┐\n",
      "│ source                         ┆ instruction                    ┆ output                         │\n",
      "│ ---                            ┆ ---                            ┆ ---                            │\n",
      "│ str                            ┆ str                            ┆ str                            │\n",
      "╞════════════════════════════════╪════════════════════════════════╪════════════════════════════════╡\n",
      "│ data/CoT/aqua_rat.json         ┆ The distance between two       ┆ Let's think about the          │\n",
      "│                                ┆ stars…                         ┆ multi-ch…                      │\n",
      "│ data/CoT/aqua_rat.json         ┆ How many ways can the letters  ┆ Let's solve the multi-choice   │\n",
      "│                                ┆ …                              ┆ q…                             │\n",
      "│ data/PoT/aqua_rat_filtered.jso ┆ A team of six entered for a    ┆ answers = ['A', 'B', 'C',      │\n",
      "│ …                              ┆ sh…                            ┆ 'D',…                          │\n",
      "│ data/CoT/gsm_rft.json          ┆ A psychiatrist has 4 patients  ┆ The second patient needs 6+5   │\n",
      "│                                ┆ …                              ┆ =…                             │\n",
      "│ data/PoT/aqua_rat_filtered.jso ┆ The radius of a wheel is 22.4  ┆ radius = 22.4                  │\n",
      "│ …                              ┆ …                              ┆ resolutions = 50…              │\n",
      "└────────────────────────────────┴────────────────────────────────┴────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "data = pl.read_json(\"/opt/tiger/MoDS/MathInstruct.json\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t1 = torch.load(\"/opt/tiger/Cherry_LLM/code_data_pre.pt\")\n",
    "print(type(t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ppl': [tensor(18.6185), 0, 0], 'sent_emb': [tensor([[-0.3425,  0.0562,  0.7246,  ..., -0.0523, -0.9365, -1.1855]],\n",
      "       dtype=torch.float16), 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(t1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"parquet\", data_files = \"/mnt/bn/data-tns-live-llm/leon/datasets/code.parquet\", split = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Create a function that takes a specific input and produces a specific output using any mathematical operators. Write corresponding code in Python.', 'input': '', 'output': 'def f(x):\\n    \"\"\"\\n    Takes a specific input and produces a specific output using any mathematical operators\\n    \"\"\"\\n    return x**2 + 3*x'}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "        \"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\"\n",
    "    ),\n",
    "    \"prompt_no_input\": (\n",
    "        \"Below is an instruction that describes a task. \"\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "        \"### Instruction:\\n{instruction}\\n\\n### Response:\"\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_function(input):\n",
    "    prompt_input, prompt_no_input = PROMPT_DICT[\"prompt_input\"], PROMPT_DICT[\"prompt_no_input\"]\n",
    "    sources = prompt_input.format_map(input) if input.get(\"input\", \"\") != \"\" else prompt_no_input.format_map(input)\n",
    "    return sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Create a function that takes a specific input and produces a specific output using any mathematical operators. Write corresponding code in Python.\n",
      "\n",
      "### Response:\n"
     ]
    }
   ],
   "source": [
    "print(format_function(dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50258, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50258, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(\"/mnt/bn/data-tns-live-llm/leon/datasets/pre-exp-code/\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[765, 681, 913, 129, 740, 723, 178, 64, 44, 176, 631, 774, 15, 38, 763, 668, 688, 847, 911, 239, 515, 333, 999, 147, 363, 956, 150, 501, 100, 871, 732, 619, 143, 507, 460, 582, 939, 449, 743, 691, 895, 482, 404, 706, 648, 179, 383, 949, 433, 898, 751, 824, 104, 189, 845, 802, 767, 496, 59, 352, 458, 931, 237, 987, 108, 141, 393, 271, 961, 394, 354, 645, 320, 519, 476, 781, 474, 524, 297, 980, 111, 726, 362, 154, 534, 166, 928, 874, 251, 351, 943, 970, 463, 359, 79, 759, 210, 235, 993, 710, 95, 741, 160, 803, 177, 967, 646, 35, 162, 203, 68, 385, 266, 731, 39, 784, 622, 806, 537, 677, 219, 54, 771, 872, 445, 83, 279, 854, 437, 312, 133, 841, 637, 690, 309, 825, 371, 343, 248, 300, 918, 296, 479, 483, 174, 84, 698, 530, 960, 563, 531, 594, 332, 651, 849, 535, 811, 926, 148, 114, 185, 369, 708, 71, 888, 838, 687, 953, 983, 288, 764, 823, 842, 41, 258, 709, 738, 262, 873, 817, 165, 466, 117, 770, 403, 254, 459, 650, 103, 951, 470, 402, 589, 954, 810, 627, 684, 497, 278, 163, 391, 596, 378, 541, 844, 574, 321, 298, 69, 429, 517, 819, 730, 19, 703, 733, 78, 794, 982, 469, 538, 821, 880, 914, 353, 146, 421, 130, 432, 226, 744, 72, 461, 511, 6, 9, 996, 689, 395, 971, 304, 484, 513, 338, 411, 431, 346, 290, 408, 11, 850, 969, 797, 202, 350, 400, 692, 642, 50, 719, 241, 183, 742, 565, 323, 562, 826, 277, 34, 836, 509, 930, 603, 102, 736, 700, 905, 324, 118, 128, 200, 409, 502, 336, 187, 657, 357, 360, 322, 269, 365, 670, 628, 848, 356, 746, 661, 32, 319, 155, 207, 173, 882, 198, 276, 523, 820, 65, 430, 1, 481, 361, 673, 902, 36, 621, 572, 412, 397, 978, 291, 131, 635, 539, 169, 257, 973, 903, 57, 265, 830, 966, 664, 590, 192, 105, 529, 253, 793, 61, 855, 21, 342, 249, 549, 472, 907, 40, 745, 776, 899, 925, 480, 225, 527, 29, 112, 448, 49, 446, 91, 418, 28, 126, 721, 486, 73, 718, 543, 67, 760, 119, 294, 417, 222, 620, 82, 62, 600, 814, 946, 663, 921, 140, 827, 647, 629, 878, 250, 779, 66, 7, 787, 649, 566, 525, 704, 944, 487, 93, 390, 186, 184, 747, 399, 286, 416, 835, 593, 828, 344, 734, 227, 159, 23, 869, 922, 441, 587, 475, 318, 728, 377, 581, 231, 243, 623, 491, 720, 671, 244, 935, 18, 669, 952, 43, 805, 90, 569, 375, 405, 536, 727, 592, 234, 672, 610, 410, 48, 940, 495, 652, 500, 193, 465, 201, 246, 542, 14, 843, 3, 401, 694, 544, 180, 988, 5, 586, 467, 89, 426, 997, 567, 962, 46, 773, 750, 274, 959, 456, 716, 376, 74, 660, 386, 268, 488, 540, 613, 711, 172, 388, 263, 471, 341, 348, 228, 986, 229, 508, 945, 157, 910, 908, 546, 607, 904, 675, 407, 42, 674, 60, 287, 699, 558, 571, 451, 490, 941, 25, 190, 851, 275, 780, 339, 862, 975, 116, 618, 860, 876, 120, 901, 624, 436, 977, 679, 492, 175, 919, 639, 452, 96, 115, 579, 123, 285, 516, 335, 559, 578, 950, 209, 885, 570, 889, 142, 211, 127, 137, 31, 556, 477, 16, 413, 804, 345, 643, 612, 920, 422, 86, 299, 106, 326, 13, 957, 863, 238, 552, 655, 605, 714, 473, 224, 420, 368, 181, 20, 551, 658, 864, 896, 777, 796, 717, 662, 22, 550, 785, 8, 367, 17, 857, 693, 630, 107, 438, 561, 585, 739, 964, 762, 634, 151, 790, 990, 994, 659, 909, 468, 170, 406, 242, 788, 261, 947, 923, 331, 92, 220, 638, 695, 382, 818, 641, 595, 230, 520, 890, 236, 334, 188, 113, 576, 311, 653, 617, 991, 447, 813, 506, 933, 568, 604, 259, 853, 583, 218, 256, 301, 599, 440, 808, 152, 164, 877, 735, 26, 197, 786, 303, 213, 598, 601, 317, 666, 976, 94, 205, 33, 55, 161, 891, 325, 989, 683, 347, 216, 315, 894, 856, 121, 968, 58, 63, 678, 136, 686, 204, 518, 778, 756, 444, 514, 457, 881, 676, 912, 929, 208, 88, 526, 30, 423, 995, 233, 37, 934, 942, 892, 414, 724, 217, 12, 974, 886, 713, 293, 85, 194, 454, 4, 252, 505, 584, 573, 965, 936, 632, 355, 247, 875, 381, 337, 963, 264, 837, 625, 798, 769, 214, 972, 2, 450, 305, 948, 328, 124, 626, 522, 195, 215, 861, 245, 270, 284, 145, 636, 834, 494, 702, 749, 829, 428, 591, 782, 840, 379, 800, 349, 822, 754, 489, 833, 396, 280, 654, 199, 597, 893, 737, 373, 554, 493, 255, 680, 171, 455, 478, 366, 0, 289, 330, 866, 633, 614, 464, 547, 906, 799, 138, 588, 310, 937, 795, 272, 260, 387, 196, 313, 504, 715, 427, 512, 398, 101, 528, 884, 789, 575, 314, 640, 981, 611, 831, 755, 424, 897, 52, 77, 453, 752, 499, 602, 122, 307, 24, 485, 979, 958, 10, 340, 206, 308, 97, 608, 156, 712, 110, 748, 498, 705, 887, 758, 76, 306, 364, 685, 555, 374, 533, 917, 223, 132, 327, 859, 168, 865, 292, 370, 722, 609, 938, 832, 707, 434, 553, 656, 144, 807, 757, 158, 53, 283, 167, 221, 240, 932, 644, 87, 358, 915, 182, 809, 302, 998, 135, 564, 281, 435, 870, 580, 665, 725, 232, 81, 27, 267, 815, 316, 56, 80, 442, 282, 191, 443, 372, 389, 992, 697, 521, 879, 985, 51, 791, 615, 867, 812, 916, 577, 462, 616, 419, 439, 109, 212, 852, 701, 816, 149, 425, 153, 548, 783, 125, 846, 380, 868, 139, 510, 329, 384, 295, 984, 766, 606, 955, 47, 761, 545, 883, 775, 682, 273, 839, 753, 415, 696, 792, 801, 532, 927, 667, 70, 858, 45, 729, 75, 557, 900, 98, 924, 134, 560, 772, 99, 503, 392, 768]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.load(\"/mnt/bn/data-tns-live-llm/leon/datasets/code_data_cherry.pt\")\n",
    "ifd = [d[\"ppl\"][2]/d[\"ppl\"][1] for d in data]\n",
    "idxs = sorted(range(len(ifd)), key=lambda i: ifd[i], reverse=True)\n",
    "print(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[413, 966, 127, 357, 836, 200, 210, 947, 72, 377, 790, 473, 130, 674, 622, 972, 653, 594, 266, 416, 219, 655, 639, 654, 93, 757, 970, 404, 656, 358, 288, 106, 209, 151, 815, 49, 348, 513, 984, 732, 948, 96, 269, 501, 279, 778, 102, 994, 579, 478, 569, 608, 826, 687, 104, 811, 50, 399, 591, 927, 807, 254, 487, 647, 382, 388, 83, 201, 481, 849, 694, 548, 842, 679, 101, 759, 276, 318, 531, 466, 894, 573, 722, 690, 954, 511, 902, 781, 211, 431, 296, 35, 89, 981, 983, 658, 19, 714, 820, 597, 710, 439, 55, 999, 527, 890, 664, 542, 546, 483, 297, 395, 944, 528, 384, 22, 635, 910, 265, 270, 207, 977, 249, 470, 33, 274, 312, 574, 817, 832, 16, 969, 975, 758, 870, 66, 955, 568, 138, 614, 262, 878, 489, 88, 328, 562, 630, 610, 345, 823, 621, 551, 491, 691, 967, 461, 323, 187, 797, 800, 899, 595, 686, 672, 107, 818, 673, 289, 427, 194, 719, 728, 779, 843, 803, 612, 976, 845, 44, 746, 257, 13, 667, 361, 903, 195, 452, 925, 834, 907, 480, 602, 449, 286, 225, 99, 352, 373, 3, 880, 841, 152, 223, 240, 179, 342, 302, 423, 484, 243, 625, 220, 534, 81, 669, 868, 173, 159, 706, 385, 838, 469, 923, 922, 73, 28, 9, 150, 467, 987, 365, 335, 950, 97, 320, 663, 699, 350, 53, 417, 530, 316, 867, 149, 988, 780, 76, 492, 905, 633, 775, 928, 745, 400, 751, 458, 157, 453, 762, 941, 720, 231, 873, 216, 505, 21, 788, 248, 773, 113, 607, 295, 833, 893, 218, 648, 471, 993, 203, 509, 380, 313, 112, 90, 401, 718, 641, 58, 205, 25, 84, 476, 951, 155, 544, 305, 268, 589, 835, 881, 47, 791, 889, 441, 577, 133, 550, 931, 643, 611, 943, 918, 901, 171, 116, 535, 103, 60, 246, 703, 875, 650, 115, 394, 537, 688, 968, 964, 721, 555, 330, 27, 959, 978, 512, 657, 37, 525, 709, 464, 991, 410, 808, 956, 86, 973, 253, 281, 135, 794, 502, 810, 615, 949, 244, 514, 980, 355, 301, 912, 652, 74, 874, 145, 670, 59, 882, 876, 459, 871, 844, 752, 8, 717, 146, 982, 590, 105, 154, 693, 222, 167, 696, 38, 953, 63, 805, 755, 974, 43, 592, 661, 495, 767, 131, 148, 124, 682, 263, 277, 756, 18, 176, 819, 78, 314, 183, 628, 412, 675, 256, 272, 827, 698, 381, 136, 660, 856, 472, 56, 175, 440, 578, 585, 359, 62, 942, 924, 507, 182, 379, 570, 332, 869, 235, 565, 516, 448, 892, 498, 640, 606, 763, 536, 802, 887, 5, 402, 390, 603, 572, 405, 583, 68, 824, 828, 393, 434, 303, 376, 271, 336, 517, 425, 438, 327, 474, 315, 744, 599, 353, 445, 40, 339, 85, 165, 230, 300, 79, 291, 587, 613, 523, 831, 557, 117, 321, 957, 198, 793, 255, 140, 914, 311, 362, 632, 816, 120, 324, 1, 186, 601, 561, 692, 298, 398, 549, 71, 898, 65, 29, 564, 193, 190, 479, 737, 197, 252, 290, 529, 503, 623, 799, 760, 900, 310, 486, 742, 822, 143, 162, 813, 341, 783, 638, 926, 251, 960, 545, 468, 727, 372, 346, 128, 729, 180, 294, 409, 166, 935, 77, 435, 432, 338, 519, 396, 308, 989, 963, 119, 378, 91, 15, 392, 938, 776, 554, 837, 292, 437, 634, 326, 705, 770, 998, 329, 897, 618, 707, 168, 962, 683, 344, 851, 586, 374, 94, 946, 177, 369, 109, 386, 0, 895, 541, 539, 433, 351, 160, 408, 582, 558, 213, 95, 368, 940, 750, 593, 716, 237, 847, 278, 4, 20, 331, 224, 806, 919, 825, 617, 111, 936, 430, 861, 885, 857, 749, 39, 403, 343, 208, 500, 952, 144, 463, 191, 540, 801, 735, 354, 228, 45, 990, 7, 538, 877, 17, 785, 92, 454, 646, 82, 933, 689, 795, 736, 174, 855, 57, 375, 576, 170, 571, 840, 934, 443, 666, 532, 242, 363, 734, 147, 685, 724, 11, 753, 677, 789, 118, 769, 904, 631, 787, 322, 6, 156, 98, 54, 123, 521, 283, 30, 356, 995, 917, 580, 214, 860, 662, 913, 731, 233, 185, 996, 293, 204, 971, 604, 645, 979, 671, 865, 854, 229, 680, 992, 774, 309, 69, 853, 202, 504, 482, 581, 733, 153, 859, 518, 285, 839, 234, 684, 786, 620, 883, 325, 961, 475, 626, 496, 488, 754, 192, 347, 921, 239, 337, 930, 605, 317, 588, 444, 909, 784, 908, 765, 137, 411, 340, 741, 864, 619, 14, 181, 267, 704, 189, 713, 12, 730, 814, 508, 247, 896, 299, 879, 169, 695, 122, 739, 830, 499, 526, 275, 522, 846, 651, 132, 221, 142, 738, 916, 866, 364, 134, 460, 450, 424, 886, 520, 126, 397, 712, 497, 446, 217, 725, 141, 747, 915, 172, 48, 596, 260, 10, 862, 414, 609, 665, 428, 31, 457, 226, 777, 420, 456, 809, 872, 494, 697, 238, 419, 227, 199, 600, 415, 743, 114, 649, 490, 383, 406, 559, 506, 212, 206, 236, 821, 121, 422, 188, 261, 782, 370, 304, 161, 804, 34, 273, 426, 700, 264, 567, 462, 858, 215, 23, 32, 447, 139, 164, 319, 87, 891, 510, 884, 280, 812, 644, 848, 196, 389, 852, 158, 349, 642, 108, 258, 792, 465, 708, 850, 110, 306, 711, 906, 556, 232, 945, 36, 429, 334, 485, 307, 26, 715, 52, 726, 911, 421, 2, 259, 986, 477, 676, 42, 367, 46, 371, 659, 637, 250, 575, 129, 932, 125, 598, 442, 668, 553, 387, 584, 333, 80, 629, 287, 636, 888, 566, 178, 627, 772, 64, 75, 701, 965, 702, 920, 985, 764, 863, 768, 740, 67, 543, 678, 391, 929, 829, 51, 163, 766, 723, 41, 241, 407, 552, 796, 436, 360, 70, 493, 937, 547, 563, 282, 616, 761, 451, 515, 624, 771, 681, 939, 798, 455, 997, 284, 958, 366, 524, 61, 418, 184, 560, 100, 24, 533, 245, 748]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"/mnt/bn/data-tns-live-llm/leon/datasets/code-quality-evaluation.json\", \"r\") as f:\n",
    "    d1 = json.loads(f.read())\n",
    "scores = [d[\"reward_score\"] for d in d1[:1000]]\n",
    "sidxs = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)\n",
    "print(sidxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.421875\n"
     ]
    }
   ],
   "source": [
    "print(scores[413])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
